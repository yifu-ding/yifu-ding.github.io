# Selected & Recent Publications

This file maintains a list of selected and recent publications for the personal homepage.

## Paper ID System

Each paper is assigned a unique ID for easy reference and maintenance.

---

## Selected & Recent Work

### P001
**Title**: Dynamic Parallel Tree Search for Efficient LLM Reasoning  
**Authors**: Y Ding, W Jiang, S Liu, Y Jing, J Guo, Y Wang, J Zhang, Z Wang, Z Liu, et al.  
**Venue**: arXiv preprint arXiv:2502.16235  
**Year**: 2025  
**Citations**: 20  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:YOwf2qJgpHMC

### P002
**Title**: A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms  
**Authors**: R Gong, Y Ding, Z Wang, C Lv, X Zheng, J Du, Y Yong, S Gu, H Qin, et al.  
**Venue**: Neural Networks, 107856  
**Year**: 2025  
**Citations**: 31  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:3fE2CSJIrl8C

### P003
**Title**: PTQ4SAM: Post-Training Quantization for Segment Anything  
**Authors**: C Lv, H Chen, J Guo, Y Ding, X Liu  
**Venue**: CVPR 2024  
**Year**: 2024  
**Citations**: 43  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:5nxA0vEk-isC

### P004
**Title**: Reg-PTQ: Regression-specialized Post-training Quantization for Fully Quantized Object Detector  
**Authors**: Y Ding, W Feng, C Chen, J Guo, X Liu  
**Venue**: CVPR 2024  
**Year**: 2024  
**Citations**: 16  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:8k81kl-MbHgC

### P005
**Title**: Compressing Large Language Models by Joint Sparsification and Quantization  
**Authors**: J Guo, J Wu, Z Wang, J Liu, G Yang, Y Ding, R Gong, H Qin, X Liu  
**Venue**: ICML 2024  
**Year**: 2024  
**Citations**: 40  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:0EnyYjriUFMC

### P006
**Title**: DB-LLM: Accurate Dual-Binarization for Efficient LLMs  
**Authors**: H Chen, C Lv, L Ding, H Qin, X Zhou, Y Ding, X Liu, M Zhang, J Guo, X Liu, et al.  
**Venue**: arXiv preprint arXiv:2402.11960  
**Year**: 2024  
**Citations**: 34  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:Se3iqnhoufwC

### P007
**Title**: QuantSR: Accurate Low-bit Quantization for Efficient Image Super-Resolution  
**Authors**: H Qin, Y Zhang, Y Ding, X Liu, M Danelljan, F Yu  
**Venue**: NeurIPS 2023  
**Year**: 2023  
**Citations**: 78  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:hqOjcs7Dif8C

### P008
**Title**: BiBench: Benchmarking and Analyzing Network Binarization  
**Authors**: H Qin, M Zhang, Y Ding, A Li, Z Cai, Z Liu, F Yu, X Liu  
**Venue**: ICML 2023  
**Year**: 2023  
**Citations**: 68  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:ufrVoPGSRksC

### P009
**Title**: Diverse Sample Generation: Pushing the Limit of Generative Data-Free Quantization  
**Authors**: H Qin, Y Ding, X Zhang, J Wang, X Liu, J Lu  
**Venue**: IEEE TPAMI 2023  
**Year**: 2023  
**Citations**: 110  
**Scholar Link**: https://scholar.google.ca/citations?view_op=view_citation&user=RCEI1r0AAAAJ&citation_for_view=RCEI1r0AAAAJ:roLk4NBRz8UC

---

## Additional Notable Papers (Not on Homepage)

### P010
**Title**: QVGen: Pushing the Limit of Quantized Video Generative Models  
**Authors**: Y Huang, R Gong, J Liu, Y Ding, C Lv, H Qin, J Zhang  
**Venue**: arXiv preprint arXiv:2505.11497  
**Year**: 2025  
**Citations**: 6

### P011
**Title**: VORTA: Efficient Video Diffusion via Routing Sparse Attention  
**Authors**: W Sun, RC Tu, Y Ding, Z Jin, J Liao, S Liu, D Tao  
**Venue**: arXiv preprint arXiv:2505.18809  
**Year**: 2025  
**Citations**: 4

### P012
**Title**: Llmcbench: Benchmarking Large Language Model Compression for Efficient Deployment  
**Authors**: G Yang, C He, J Guo, J Wu, Y Ding, A Liu, H Qin, P Ji, X Liu  
**Venue**: NeurIPS 2024  
**Year**: 2024  
**Citations**: 15

### P013
**Title**: BifsmnV2: Pushing Binary Neural Networks for Keyword Spotting to Real-Network Performance  
**Authors**: H Qin, X Ma, Y Ding, X Li, Y Zhang, Z Ma, J Wang, J Luo, X Liu  
**Venue**: IEEE TNNLS 2023  
**Year**: 2023  
**Citations**: 43

---

## Statistics Summary

**Last Updated**: January 2026

- Total Citations: 1290+
- h-index: 17
- i10-index: 23
- Total Publications: 23+

**Research Focus**:
- Neural Network Compression
- Model Quantization
- Efficient Deep Learning
- Low-bit Models
- Large Language Models

**Affiliations**:
- Beihang University (PhD Candidate)
- Email: @buaa.edu.cn

---

## Update Instructions

To update this list:

1. Check Google Scholar: https://scholar.google.ca/citations?user=RCEI1r0AAAAJ
2. Add new papers with sequential Paper IDs (P014, P015, etc.)
3. Update citation counts for existing papers
4. Update the statistics summary
5. Update the corresponding HTML file (index.html) with the new data
6. Keep 9-12 papers displayed on the homepage (most impactful and recent)

## Selection Criteria for Homepage Display

Papers should be selected based on:
- Recent publications (2023-2025)
- High citation count (>15 citations preferred)
- Top-tier venues (CVPR, ICCV, NeurIPS, ICML, TPAMI, etc.)
- First-author or major contribution papers
- Representative of research focus areas

